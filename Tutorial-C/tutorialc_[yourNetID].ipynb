{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"1RY_qNlxSbsT"},"source":["# Extra credit: Building our own network\n","In this extra credit assignment, you will try to build your own network for application. The steps are following: \n","1. Loading the package and IMDB data.\n","2. Build the network base on description. In this step, you need to add codes to the network building.\n","3. validate your network.\n","Please follow these 3 steps in order, and add codes to build the model in the corresponding place. \n"]},{"cell_type":"code","metadata":{"id":"HiMwvtimQyhU"},"source":["import keras\n","keras.__version__"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D0wKi-V4So3f"},"source":["from keras.datasets import imdb\n","\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ttN5a-hiTE_n"},"source":["## Preparing the data\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"fAKHMvgvTLYo","executionInfo":{"status":"ok","timestamp":1681065386438,"user_tz":240,"elapsed":8143,"user":{"displayName":"Yijue Wang","userId":"11373801132281748436"}}},"source":["import numpy as np\n","\n","def vectorize_sequences(sequences, dimension=10000):\n","    # Create an all-zero matrix of shape (len(sequences), dimension)\n","    results = np.zeros((len(sequences), dimension))\n","    for i, sequence in enumerate(sequences):\n","        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n","    return results\n","\n","# Our vectorized training data\n","x_train = vectorize_sequences(train_data)\n","# Our vectorized test data\n","x_test = vectorize_sequences(test_data)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYEO_QN_URTK"},"source":["x_train[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHFn0awRXUTi","executionInfo":{"status":"ok","timestamp":1681065386439,"user_tz":240,"elapsed":5,"user":{"displayName":"Yijue Wang","userId":"11373801132281748436"}}},"source":["# Our vectorized labels\n","y_train = np.asarray(train_labels).astype('float32')\n","y_test = np.asarray(test_labels).astype('float32')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eZUi3OPSXgCo"},"source":["Now our data is ready to be fed into a neural network."]},{"cell_type":"markdown","metadata":{"id":"np3HaGlOXjNg"},"source":["## Building our network \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2T0FY05VXonD"},"source":["Here's what our network looks like:\n","\n","![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"]},{"cell_type":"markdown","metadata":{"id":"Jo6NpfDtXrdK"},"source":["And here's the Keras implementation, very similar to the MNIST example you saw previously:"]},{"cell_type":"code","metadata":{"id":"L6LlgHBeXxxU","executionInfo":{"status":"ok","timestamp":1681065387343,"user_tz":240,"elapsed":908,"user":{"displayName":"Yijue Wang","userId":"11373801132281748436"}}},"source":["from keras import models\n","from keras import layers\n","\n","model = models.Sequential()\n","model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n","#Add code here. This is the second layer with 16 nodes and  activation function relu.\n","#Add code here. This is the Third layer with 1 nodes and  activation function sigmoid."],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"KeNen50PX55T"},"source":["model.compile(optimizer='rmsprop',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H1R3pCu7X_uA"},"source":["from keras import optimizers\n","\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z7ugupyZYFn3","executionInfo":{"status":"ok","timestamp":1681065392932,"user_tz":240,"elapsed":128,"user":{"displayName":"Yijue Wang","userId":"11373801132281748436"}}},"source":["from keras import losses\n","from keras import metrics\n","\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n","              loss=losses.binary_crossentropy,\n","              metrics=[metrics.binary_accuracy])"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AowrZkByYIPa"},"source":["## Validating our approach\n","\n"]},{"cell_type":"code","metadata":{"id":"GE226W8uYJYL","executionInfo":{"status":"ok","timestamp":1681065395487,"user_tz":240,"elapsed":140,"user":{"displayName":"Yijue Wang","userId":"11373801132281748436"}}},"source":["x_val = x_train[:10000]\n","partial_x_train = x_train[10000:]\n","\n","y_val = y_train[:10000]\n","partial_y_train = y_train[10000:]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"XO8ty9UIYOPt"},"source":["history = model.fit(partial_x_train,\n","                    partial_y_train,\n","                    epochs=20,\n","                    batch_size=512,\n","                    validation_data=(x_val, y_val))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zcoAZMEYVgi"},"source":["history_dict = history.history\n","history_dict.keys()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bhg-WYlCZA5V"},"source":["import matplotlib.pyplot as plt\n","\n","acc = history.history['binary_accuracy']\n","val_acc = history.history['val_binary_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","# \"bo\" is for \"blue dot\"\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","# b is for \"solid blue line\"\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AiNrmE9PZC8N"},"source":["plt.clf()   # clear figure\n","acc_values = history_dict['binary_accuracy']\n","val_acc_values = history_dict['val_binary_accuracy']\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FUXPLV_NZHJd"},"source":["model = models.Sequential()\n","model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n","model.add(layers.Dense(16, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='rmsprop',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train, epochs=4, batch_size=512)\n","results = model.evaluate(x_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"biOftRorZI7r"},"source":["results"],"execution_count":null,"outputs":[]}]}